{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libararies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import face_recognition\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames :  [464, 520, 420, 456, 401, 461, 314, 350, 529, 303, 469, 326, 459, 479, 534, 520, 326, 459, 534, 350, 529, 303, 469, 303, 469, 350, 529, 479, 534, 459]\n",
      "Total Number of Videos :  30\n",
      "Average frames per video :  436.6\n"
     ]
    }
   ],
   "source": [
    "# finding the number of frames for each video in dataset.\n",
    "video_files = glob.glob('/Users/karthiksagar/DEEP-FAKE-DETECTION/dataset-real/*.mp4')\n",
    "video_files1 = glob.glob('/Users/karthiksagar/DEEP-FAKE-DETECTION/dataset-fake/*.mp4')\n",
    "video_files += video_files1\n",
    "\n",
    "frame_count = []\n",
    "for video_file in video_files:\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    if (int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) < 150):\n",
    "        video_files.remove(video_file)\n",
    "        continue\n",
    "    frame_count.append(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "\n",
    "print(\"Frames : \", frame_count)\n",
    "print(\"Total Number of Videos : \", len(frame_count))\n",
    "print(\"Average frames per video : \", np.mean(frame_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXTRACTING FACE CROPPED IMAGES FROM VIDEOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import face_recognition\n",
    "\n",
    "# Define the paths to the folders containing the videos\n",
    "videos_folder_1 = \"/Users/karthiksagar/Deep-Fake-Detection/FF++/fake\"\n",
    "videos_folder_2 = \"/Users/karthiksagar/Deep-Fake-Detection/FF++/real\"\n",
    "\n",
    "# Define the path to the output folder for face-only videos\n",
    "output_folder1 = \"/Users/karthiksagar/Deep-Fake-Detection/FF++/Face-Image-Fake\"\n",
    "output_folder2 = \"/Users/karthiksagar/Deep-Fake-Detection/FF++/Face-Image-Real\"\n",
    "\n",
    "# Function to extract faces from a video and save them as images\n",
    "def extract_faces_from_video(video_path, output_folder):\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Open the video file\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "    frames_processed = 0\n",
    "\n",
    "    # Read until video is completed\n",
    "    while frame_count < 5:\n",
    "        # Read a single frame\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break  # Break the loop if no more frames are available\n",
    "\n",
    "        # Convert frame to RGB (face_recognition library requires RGB format)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Find faces in the frame\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "\n",
    "        # If faces are found, extract and save them\n",
    "        for top, right, bottom, left in face_locations:\n",
    "            # Extract the face region\n",
    "            face_image = frame[top:bottom, left:right]\n",
    "\n",
    "            # Write the face image to the output folder\n",
    "            output_path = os.path.join(output_folder, f\"{os.path.basename(video_path)}_frame_{frame_count}.jpg\")\n",
    "            cv2.imwrite(output_path, face_image)\n",
    "\n",
    "            # Increment frame count\n",
    "            frame_count += 1\n",
    "            frames_processed += 1\n",
    "        \n",
    "        if frames_processed == 5:\n",
    "            break\n",
    "\n",
    "    # Release the video capture object\n",
    "    video_capture.release()\n",
    "\n",
    "# Process videos in the first folder\n",
    "for video_file in os.listdir(videos_folder_1):\n",
    "    if video_file.endswith(\".mp4\"):\n",
    "        video_path = os.path.join(videos_folder_1, video_file)\n",
    "        extract_faces_from_video(video_path, output_folder1)\n",
    "\n",
    "# Process videos in the second folder\n",
    "for video_file in os.listdir(videos_folder_2):\n",
    "    if video_file.endswith(\".mp4\"):\n",
    "        video_path = os.path.join(videos_folder_2, video_file)\n",
    "        extract_faces_from_video(video_path, output_folder2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXTRACTING FACE CROPPED VIDEOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos already present:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      " 10%|█         | 1/10 [01:42<15:26, 102.93s/it]OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      " 20%|██        | 2/10 [03:30<14:07, 105.93s/it]OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      " 30%|███       | 3/10 [05:19<12:30, 107.23s/it]OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      " 40%|████      | 4/10 [07:03<10:34, 105.73s/it]OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      " 50%|█████     | 5/10 [08:49<08:49, 105.91s/it]OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      " 60%|██████    | 6/10 [10:33<07:00, 105.23s/it]OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      " 70%|███████   | 7/10 [12:18<05:15, 105.14s/it]OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      " 80%|████████  | 8/10 [14:04<03:30, 105.35s/it]OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      " 90%|█████████ | 9/10 [15:50<01:45, 105.58s/it]OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|██████████| 10/10 [17:35<00:00, 105.54s/it]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import face_recognition\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to extract frames from a video\n",
    "def extract_frames(video_path):\n",
    "    frames = []\n",
    "    vidObj = cv2.VideoCapture(video_path) \n",
    "    success = True\n",
    "    while success:\n",
    "        success, image = vidObj.read()\n",
    "        if success:\n",
    "            frames.append(image)\n",
    "    return frames\n",
    "\n",
    "# Function to detect faces in frames and save cropped face video clips\n",
    "def create_face_videos(video_paths, output_dir):\n",
    "    already_present_count = len(glob.glob(os.path.join(output_dir, '*.mp4')))\n",
    "    print(\"Number of videos already present: \", already_present_count)\n",
    "    \n",
    "    for video_path in tqdm(video_paths):\n",
    "        out_path = os.path.join(output_dir, os.path.basename(video_path))\n",
    "        if os.path.exists(out_path):\n",
    "            print(\"File already exists: \", out_path)\n",
    "            continue\n",
    "        \n",
    "        frames = extract_frames(video_path)\n",
    "        frame_count = len(frames)\n",
    "        out = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc('M','J','P','G'), 30, (112, 112))\n",
    "        \n",
    "        for idx, frame in enumerate(frames):\n",
    "            if idx <= 150:  # Process only the first 150 frames\n",
    "                faces = face_recognition.face_locations(frame)\n",
    "                if faces:\n",
    "                    top, right, bottom, left = faces[0]\n",
    "                    face_frame = frame[top:bottom, left:right, :]\n",
    "                    resized_face = cv2.resize(face_frame, (112, 112))\n",
    "                    out.write(resized_face)\n",
    "        \n",
    "        out.release()\n",
    "\n",
    "# Example usage\n",
    "video_paths = glob.glob(\"/Users/karthiksagar/Deep-Fake-Detection/Sample-Dataset/real/*.mp4\")\n",
    "output_directory = '/Users/karthiksagar/Deep-Fake-Detection/Sample-Dataset/cropped'\n",
    "create_face_videos(video_paths, output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos already present:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      " 10%|█         | 1/10 [01:43<15:28, 103.17s/it]OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      " 20%|██        | 2/10 [03:32<14:16, 107.02s/it]OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      " 30%|███       | 3/10 [05:17<12:22, 106.01s/it]OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      " 40%|████      | 4/10 [07:00<10:29, 104.91s/it]OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      " 50%|█████     | 5/10 [08:43<08:40, 104.10s/it]OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      " 60%|██████    | 6/10 [10:27<06:55, 103.94s/it]OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      " 70%|███████   | 7/10 [12:14<05:15, 105.19s/it]OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      " 80%|████████  | 8/10 [14:01<03:31, 105.52s/it]OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      " 90%|█████████ | 9/10 [15:47<01:45, 105.84s/it]OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|██████████| 10/10 [17:34<00:00, 105.42s/it]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import face_recognition\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to extract frames from a video\n",
    "def extract_frames(video_path):\n",
    "    frames = []\n",
    "    vidObj = cv2.VideoCapture(video_path) \n",
    "    success = True\n",
    "    while success:\n",
    "        success, image = vidObj.read()\n",
    "        if success:\n",
    "            frames.append(image)\n",
    "    return frames\n",
    "\n",
    "# Function to detect faces in frames and save cropped face video clips\n",
    "def create_face_videos(video_paths, output_dir):\n",
    "    already_present_count = len(glob.glob(os.path.join(output_dir, '*.mp4')))\n",
    "    print(\"Number of videos already present: \", already_present_count)\n",
    "    \n",
    "    for video_path in tqdm(video_paths):\n",
    "        out_path = os.path.join(output_dir, os.path.basename(video_path))\n",
    "        if os.path.exists(out_path):\n",
    "            print(\"File already exists: \", out_path)\n",
    "            continue\n",
    "        \n",
    "        frames = extract_frames(video_path)\n",
    "        frame_count = len(frames)\n",
    "        out = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc('M','J','P','G'), 30, (112, 112))\n",
    "        \n",
    "        for idx, frame in enumerate(frames):\n",
    "            if idx <= 150:  # Process only the first 150 frames\n",
    "                faces = face_recognition.face_locations(frame)\n",
    "                if faces:\n",
    "                    top, right, bottom, left = faces[0]\n",
    "                    face_frame = frame[top:bottom, left:right, :]\n",
    "                    resized_face = cv2.resize(face_frame, (112, 112))\n",
    "                    out.write(resized_face)\n",
    "        \n",
    "        out.release()\n",
    "\n",
    "# Example usage\n",
    "video_paths = glob.glob(\"/Users/karthiksagar/Deep-Fake-Detection/Sample-Dataset/fake/*.mp4\")\n",
    "output_directory = '/Users/karthiksagar/Deep-Fake-Detection/Sample-Dataset/cropped/fake'\n",
    "create_face_videos(video_paths, output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
