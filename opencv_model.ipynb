{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import torch.nn as nn\n",
    "# from Model import Model\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_classes=2, latent_dim=2048, lstm_layers=1, hidden_dim=2048, bidirectional=False):\n",
    "        super(Model, self).__init__()\n",
    "        model = models.resnext50_32x4d(pretrained=True)  # Residual Network CNN\n",
    "        self.feature_extractor = nn.Sequential(*list(model.children())[:-2])\n",
    "        self.lstm = nn.LSTM(latent_dim, hidden_dim, lstm_layers, bidirectional)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.dp = nn.Dropout(0.4)\n",
    "        self.linear1 = nn.Linear(2048, num_classes)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.dp(self.linear1(x))\n",
    "    \n",
    "# Load the deepfake detection model\n",
    "model_path = \"saved_best_model/best-checkpoint-model.pt\"\n",
    "model = torch.load(model_path)\n",
    "# model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "# model.cuda()\n",
    "\n",
    "# Transform settings for the model input\n",
    "im_size = 224\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((im_size, im_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "def process_frame(frame):\n",
    "    \"\"\"Preprocess frame for model input.\"\"\"\n",
    "    frame_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))  # Convert frame to PIL format\n",
    "    frame_tensor = transform(frame_pil).unsqueeze(0).cuda()  # Apply transforms and add batch dimension\n",
    "    return frame_tensor\n",
    "\n",
    "def predict(frame_tensor):\n",
    "    \"\"\"Run frame through the model and get the prediction.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        logits = model(frame_tensor)\n",
    "        sm = nn.Softmax(dim=1)\n",
    "        probabilities = sm(logits)\n",
    "        confidence, prediction = torch.max(probabilities, dim=1)\n",
    "    \n",
    "    return prediction.item(), confidence.item() * 100\n",
    "\n",
    "# OpenCV video capture\n",
    "cap = cv2.VideoCapture(0)  # Capture video from the default camera (use 0 for the default camera)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()  # Capture frame-by-frame\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Process the frame\n",
    "    frame_tensor = process_frame(frame)\n",
    "    \n",
    "    # Get prediction from the model\n",
    "    prediction, confidence = predict(frame_tensor)\n",
    "    \n",
    "    # Display the prediction on the frame\n",
    "    label = \"Real\" if prediction == 1 else \"Fake\"\n",
    "    label_text = f\"Prediction: {label}, Confidence: {confidence:.2f}%\"\n",
    "    \n",
    "    # Put text on the frame\n",
    "    cv2.putText(frame, label_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0) if prediction == 1 else (0, 0, 255), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Deepfake Detection', frame)\n",
    "\n",
    "    # Break the loop on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture when everything is done\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "import torch.nn as nn\n",
    "from Model import Model\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_classes=2, latent_dim=2048, lstm_layers=1, hidden_dim=2048, bidirectional=False):\n",
    "        super(Model, self).__init__()\n",
    "        model = models.resnext50_32x4d(pretrained=True)  # Residual Network CNN\n",
    "        self.model = nn.Sequential(*list(model.children())[:-2])\n",
    "        self.lstm = nn.LSTM(latent_dim, hidden_dim, lstm_layers, bidirectional)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.dp = nn.Dropout(0.4)\n",
    "        self.linear1 = nn.Linear(2048, num_classes)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.dp(self.linear1(x))\n",
    "\n",
    "# Load the deepfake detection model\n",
    "model_path = \"/Users/karthiksagar/DeepFake-Detection/saved_best_model/best-checkpoint-model.pt\"\n",
    "# model = Model()\n",
    "\n",
    "# Ensure the model is loaded on CPU\n",
    "model=torch.load(model_path, map_location=torch.device('cpu'))\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Transform settings for the model input\n",
    "im_size = 224\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((im_size, im_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "def process_frame(frame):\n",
    "    \"\"\"Preprocess frame for model input.\"\"\"\n",
    "    frame_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))  # Convert frame to PIL format\n",
    "    frame_tensor = transform(frame_pil).unsqueeze(0)  # Apply transforms and add batch dimension (no .cuda())\n",
    "    return frame_tensor\n",
    "\n",
    "def predict(frame_tensor):\n",
    "    \"\"\"Run frame through the model and get the prediction.\"\"\"\n",
    "    with torch.no_grad():  # No need for gradients during inference\n",
    "        logits = model(frame_tensor)  # Model forward pass (no .cuda())\n",
    "        sm = nn.Softmax(dim=1)\n",
    "        probabilities = sm(logits)\n",
    "        confidence, prediction = torch.max(probabilities, dim=1)\n",
    "    \n",
    "    return prediction.item(), confidence.item() * 100\n",
    "\n",
    "# OpenCV video capture\n",
    "cap = cv2.VideoCapture(0)  # Capture video from the default camera (use 0 for the default camera)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()  # Capture frame-by-frame\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Process the frame\n",
    "    frame_tensor = process_frame(frame)\n",
    "    \n",
    "    # Get prediction from the model\n",
    "    prediction, confidence = predict(frame_tensor)\n",
    "    \n",
    "    # Display the prediction on the frame\n",
    "    label = \"Real\" if prediction == 1 else \"Fake\"\n",
    "    label_text = f\"Prediction: {label}, Confidence: {confidence:.2f}%\"\n",
    "    \n",
    "    # Put text on the frame\n",
    "    cv2.putText(frame, label_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0) if prediction == 1 else (0, 0, 255), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Deepfake Detection', frame)\n",
    "\n",
    "    # Break the loop on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture when everything is done\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
