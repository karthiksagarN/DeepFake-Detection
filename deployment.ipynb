{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"margin: 0; padding: 5px; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none;\">\n",
       "  <div style=\"margin: 0; padding: 0; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none;\">\n",
       "    You're <span style=\"margin: 0; padding: 0; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none; color: #15803d; font-weight: bold;\">connected</span> to Modelbit as karthik.sagarn@gmail.com.\n",
       "    Workspace: <span style=\"margin: 0; padding: 0; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: monospace; background: none; font-weight: bold; color: #845B99;\">karthiksagar</span>.\n",
       "    \n",
       "      Region: <span style=\"margin: 0; padding: 0; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: monospace; background: none; font-weight: bold; color: #845B99;\">us-east-1</span>\n",
       "    \n",
       "    Branch: <span style=\"margin: 0; padding: 0; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: monospace; background: none; font-weight: bold; color: #845B99;\">main</span>\n",
       "\t</div>\n",
       "  \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import modelbit\n",
    "mb = modelbit.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REAL TIME MODEL DEPLOYMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms, models\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_classes=2, latent_dim=2048, lstm_layers=1, hidden_dim=2048, bidirectional=False):\n",
    "        super(Model, self).__init__()\n",
    "        model = models.resnext50_32x4d(pretrained=True)  # Residual Network CNN\n",
    "        self.model = nn.Sequential(*list(model.children())[:-2])\n",
    "        self.lstm = nn.LSTM(latent_dim, hidden_dim, lstm_layers, bidirectional)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.dp = nn.Dropout(0.4)\n",
    "        self.linear1 = nn.Linear(2048, num_classes)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.dp(self.linear1(x))\n",
    "\n",
    "def deepfake_detection(frame_base64):\n",
    "    frame_data = base64.b64decode(frame_base64)\n",
    "    frame = Image.open(BytesIO(frame_data))\n",
    "\n",
    "    im_size = 224\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((im_size, im_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "    frame = transform(frame).unsqueeze(0)\n",
    "    \n",
    "    # Load the TorchScript model\n",
    "    model_path = \"traced_model.pt\"\n",
    "    model = torch.jit.load(model_path)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        frame_tensor = frame\n",
    "        logits = model(frame_tensor)\n",
    "        sm = nn.Softmax(dim=1)\n",
    "        probabilities = sm(logits)\n",
    "        confidence, prediction = torch.max(probabilities, dim=1)    \n",
    "\n",
    "    if prediction == 1:\n",
    "        result = {\n",
    "            \"status\": \"real\",\n",
    "            \"confidence\": confidence.item() * 100\n",
    "        }\n",
    "    else:\n",
    "        result = {\n",
    "            \"status\": \"fake\",\n",
    "            \"confidence\": confidence.item() * 100\n",
    "        }\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"margin: 0; padding: 5px; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none;\">\n",
       "  <div>\n",
       "    <span style=\"margin: 0; padding: 0; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none; font-weight: bold; color: #15803d;\">Deploying </span> <span style=\"margin: 0; padding: 3px; line-height: 1.75; font-size: 13px; vertical-align: baseline; list-style: none; font-family: monospace; background: none; font-weight: 400; background-color: rgba(209, 213, 219, 0.2);\">deepfake_detection</span>\n",
       "  </div>\n",
       "  \n",
       "\n",
       "  <div style=\"margin: 0; padding: 0; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none;\">Uploading dependencies...</div>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"margin: 0; padding: 5px; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none;\">\n",
       "  <div style=\"margin: 0; padding: 0; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none; font-weight: bold; color: #15803d;\">Success!</div>\n",
       "  \n",
       "    <div style=\"margin: 0; padding: 0; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none;\">\n",
       "      Deployment <span style=\"margin: 0; padding: 3px; line-height: 1.75; font-size: 13px; vertical-align: baseline; list-style: none; font-family: monospace; background: none; font-weight: 400; background-color: rgba(209, 213, 219, 0.2);\">deepfake_detection</span>\n",
       "      will be ready in  a few seconds!\n",
       "    </div>\n",
       "  \n",
       "\n",
       "  <a href=\"https://us-east-1.modelbit.com/w/karthiksagar/main/deployments/deepfake_detection/apis\" target=\"_blank\" style=\"display: inline-block; margin-top: 12px;\" >\n",
       "    <div\n",
       "      style=\"display: inline-block; background-color: #845B99; border-radius: 0.375rem; color: white; cursor: pointer; font-size: 14px; font-weight: 700; padding: 8px 16px;\"\n",
       "      onmouseenter=\"this.style.background='#714488'\"\n",
       "      onmouseleave=\"this.style.background='#845B99'\"\n",
       "    >\n",
       "      View in Modelbit\n",
       "    </div>\n",
       "  </a>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mb.deploy(deepfake_detection, extra_files={\"/Users/karthiksagar/DeepFake-Detection/saved_best_model/traced_model.pt\" : \"traced_model.pt\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UPLOAD VIDEO DEPLOYMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Model class\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_classes=2, latent_dim=2048, lstm_layers=1, hidden_dim=2048, bidirectional=False):\n",
    "        super(Model, self).__init__()\n",
    "        model = models.resnext50_32x4d(pretrained=True)  # Residual Network CNN\n",
    "        self.model = nn.Sequential(*list(model.children())[:-2])\n",
    "        self.lstm = nn.LSTM(latent_dim, hidden_dim, lstm_layers, bidirectional)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.dp = nn.Dropout(0.4)\n",
    "        self.linear1 = nn.Linear(2048, num_classes)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.dp(self.linear1(x))\n",
    "\n",
    "# Preprocessing transforms (same as during training)\n",
    "im_size = 224\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((im_size, im_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "def extract_frames(video_path, frame_count=20):\n",
    "    \"\"\"\n",
    "    Extract frames from the video at regular intervals.\n",
    "    \n",
    "    Args:\n",
    "    - video_path: Path to the video file.\n",
    "    - frame_count: Number of frames to extract.\n",
    "    \n",
    "    Returns:\n",
    "    - A list of extracted frames (PIL Images).\n",
    "    \"\"\"\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    total_frames = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_interval = total_frames // frame_count\n",
    "    \n",
    "    success, image = vidcap.read()\n",
    "    count = 0\n",
    "    \n",
    "    while success and len(frames) < frame_count:\n",
    "        if count % frame_interval == 0:\n",
    "            # Convert to PIL Image and append\n",
    "            frames.append(Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)))\n",
    "        success, image = vidcap.read()\n",
    "        count += 1\n",
    "    \n",
    "    vidcap.release()\n",
    "    return frames\n",
    "\n",
    "def preprocess_frames(frames):\n",
    "\n",
    "    preprocessed_frames = [transform(frame) for frame in frames]\n",
    "    return torch.stack(preprocessed_frames).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "def predict_video(video_path):\n",
    "\n",
    "    # Load the model\n",
    "    model_path = 'traced_model.pt'\n",
    "    model = torch.jit.load(model_path)\n",
    "    model.eval()\n",
    "    \n",
    "    # Extract and preprocess frames from the video\n",
    "    frames = extract_frames(video_path, frame_count=20)\n",
    "    frame_tensor = preprocess_frames(frames)\n",
    "    \n",
    "    # Make prediction on the frame sequence\n",
    "    with torch.no_grad():\n",
    "        logits = model(frame_tensor)\n",
    "        sm = torch.nn.Softmax(dim=1)\n",
    "        probabilities = sm(logits)\n",
    "        confidence, prediction = torch.max(probabilities, dim=1)\n",
    "    \n",
    "    result = {\n",
    "        \"status\": \"real\" if prediction.item() == 1 else \"fake\",\n",
    "        \"confidence\": confidence.item() * 100\n",
    "    }\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"margin: 0; padding: 5px; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none;\">\n",
       "  <div>\n",
       "    <span style=\"margin: 0; padding: 0; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none; font-weight: bold; color: #15803d;\">Deploying </span> <span style=\"margin: 0; padding: 3px; line-height: 1.75; font-size: 13px; vertical-align: baseline; list-style: none; font-family: monospace; background: none; font-weight: 400; background-color: rgba(209, 213, 219, 0.2);\">predict_video</span>\n",
       "  </div>\n",
       "  \n",
       "\n",
       "  <div style=\"margin: 0; padding: 0; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none;\">Uploading dependencies...</div>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"margin: 0; padding: 5px; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none;\">\n",
       "  <div style=\"margin: 0; padding: 0; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none; font-weight: bold; color: #15803d;\">Success!</div>\n",
       "  \n",
       "    <div style=\"margin: 0; padding: 0; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none;\">\n",
       "      Deployment <span style=\"margin: 0; padding: 3px; line-height: 1.75; font-size: 13px; vertical-align: baseline; list-style: none; font-family: monospace; background: none; font-weight: 400; background-color: rgba(209, 213, 219, 0.2);\">predict_video</span>\n",
       "      will be ready in  a few seconds!\n",
       "    </div>\n",
       "  \n",
       "\n",
       "  <a href=\"https://us-east-1.modelbit.com/w/karthiksagar/main/deployments/predict_video/apis\" target=\"_blank\" style=\"display: inline-block; margin-top: 12px;\" >\n",
       "    <div\n",
       "      style=\"display: inline-block; background-color: #845B99; border-radius: 0.375rem; color: white; cursor: pointer; font-size: 14px; font-weight: 700; padding: 8px 16px;\"\n",
       "      onmouseenter=\"this.style.background='#714488'\"\n",
       "      onmouseleave=\"this.style.background='#845B99'\"\n",
       "    >\n",
       "      View in Modelbit\n",
       "    </div>\n",
       "  </a>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mb.deploy(predict_video, extra_files={\"/Users/karthiksagar/DeepFake-Detection/saved_best_model/traced_model.pt\" : \"traced_model.pt\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
